{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7396d6ad",
   "metadata": {},
   "source": [
    "#### So basically hear we have 1000 restaraunt real raw labeld reviews from csv file\n",
    "\n",
    "Main task: create and train the most suitable and efficient model to detect wheather the review is positive or negative\n",
    "\n",
    "Main components: Bag of Words algorithm, Scikit-learn models, NLP libraries, models evaluation\n",
    "\n",
    "Author: Voitishyn Mykyta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15d9e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da5472ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv',delimiter='\\t',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12ea4cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1\n",
       "5     Now I am getting angry and I want my damn pho.      0\n",
       "6              Honeslty it didn't taste THAT fresh.)      0\n",
       "7  The potatoes were like rubber and you could te...      0\n",
       "8                          The fries were great too.      1\n",
       "9                                     A great touch.      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ee81d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94437be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make some cleaning of text - essential step for NLP: should be cleaned as much as possible \n",
    "# import necessary tools:\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords') # not include some non-relevent words - # already downloaded!\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# only a root of a review, simplify a review,keep the presense form of world(loved -> love)\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    review = re.sub('[^a-zA-Z]','  ',dataset['Review'][i]) # get rid of punctuations by replacing with space\n",
    "    \n",
    "    review = review.lower() # lower function - very easy\n",
    "    review = review.split() # split review in a different words\n",
    "    \n",
    "    # delete unnecessary words\n",
    "    ps = PorterStemmer()\n",
    "    # solving unexpected problem with 'not'\n",
    "    all_stopwords =  stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    # first imporvment after evaluating\n",
    "    all_stopwords.remove('any')\n",
    "    all_stopwords.remove('no')\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1099b750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow love place',\n",
       " 'crust not good',\n",
       " 'not tasti textur nasti',\n",
       " 'stop late may bank holiday rick steve recommend love',\n",
       " 'select menu great price',\n",
       " 'get angri want damn pho',\n",
       " 'honeslti tast fresh',\n",
       " 'potato like rubber could tell made ahead time kept warmer',\n",
       " 'fri great',\n",
       " 'great touch']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wow, looks better\n",
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ce6179d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checked how is it looks \n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bec24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Bag of Words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c7aa729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0]) # our result of tokinization: 1566 of words. Also can take 1000 of most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "796f25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1500)\n",
    "\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a941f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(X[0]) # here our result of reshaping the list with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c383170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62dbaeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train an naive bayes model \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a2d7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on test_set\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00a276c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an confusion matrix and print the accuracy of the model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 55 correct predictions of negative reviews\n",
    "# 91 correct predictions of positive reviews\n",
    "\n",
    "# in our case it is 73%\n",
    "# not the best option but let's try to use different classification models\n",
    "# also it's nice to check more carefully our list of stopwords and probably delete something non-relevent in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67de8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_stopwords # any,no,very,too,isn't,aren't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a374e4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - logistic regression classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d06d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 16]\n",
      " [27 76]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# all right, 5% more of accuracy - sounds nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce7362bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - K-Nearest Neignbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2d2769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 26]\n",
      " [45 58]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# not so nice, only 64,5% of accuracy, not so far away of coin probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e2dd352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - Support Vector Machine Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "397d22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 16]\n",
      " [22 81]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# very nice, more than 81% of accuracy, seems like the best model for now, but we still hava a couple of \n",
    "# classification models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e17c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - Kernel Support Vector Machine \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c72f2819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  7]\n",
      " [36 67]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 78,5% of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d9d8170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - Decision Tree Classification model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78390827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78 19]\n",
      " [30 73]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.755"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 75,5% of accuracy, maybe an average of desicion tree classifications - Random forest classification might\n",
    "# perfom better, let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36676afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=400, random_state=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try another classification model - Random Forest Classification model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 400, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54293d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88  9]\n",
      " [37 66]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 77% of accuracy, if we are going to increase the number of estimators more, the accuracy will not change "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ecb83a",
   "metadata": {},
   "source": [
    "### Final results\n",
    "\n",
    "#### So, for now the best performance has the Support Vector Machine Classification model - 81% of accuracy.\n",
    "\n",
    "81 correct predictions of negetive reviews TN\n",
    "81 correct predictions of positive reviews TP\n",
    "16 incorrect predictions of negetive reviews FN\n",
    "22 incorrect predictions of positive reviews FP\n",
    "\n",
    "Accuracy = (81+81)/(81+81+16+22) = 162/200= 0,81\n",
    "Precision =  (81 / 81 + 22) = 0,786\n",
    "Recall = (81 / 81 + 16) = 0,835\n",
    "\n",
    "F1 Score = 2 * 0,786 * 0,835 / (0,786 + 0,835) = 1,31 / 1,621 = 0,80\n",
    "\n",
    "Tried to work with all_stop_words list, changes doesn't change the performance so much\n",
    "Maybe it's better to have more reviews to train the model more successfully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
